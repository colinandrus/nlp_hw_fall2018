{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['plt', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pylab as plt\n",
    "import itertools\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/Colin/Google Drive/nyu/nlp_dsga_1011/hw1/aclImdb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_dir = \"train/pos/\"\n",
    "train_neg_dir = \"train/neg/\"\n",
    "test_pos_dir = \"test/pos/\"\n",
    "test_neg_dir = \"test/neg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read in text from dir and create label list\n",
    "def read_files_to_list(path, target):\n",
    "    text_list = []\n",
    "    files = glob.glob(path + \"*.txt\") \n",
    "    target_list = [target] * len(files)\n",
    "    for i in range(len(files)):\n",
    "        with open(files[i]) as f: \n",
    "            text_list += [f.read()]\n",
    "    return text_list, target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read in train, test data and create labels\n",
    "train_pos_text, train_pos_labels = read_files_to_list(train_pos_dir, 1)\n",
    "train_neg_text, train_neg_labels = read_files_to_list(train_neg_dir, 0)\n",
    "test_pos_text, test_pos_labels = read_files_to_list(test_pos_dir, 1)\n",
    "test_neg_text, test_neg_labels = read_files_to_list(test_neg_dir, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat pos, neg data\n",
    "# train, val data\n",
    "t_v_text = train_pos_text + train_neg_text\n",
    "t_v_labels = train_pos_labels + train_neg_labels\n",
    "# test data\n",
    "test_text = test_pos_text + test_neg_text\n",
    "test_labels = test_pos_labels + test_neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling train, val\n",
    "random.seed(39) # for reproducibility\n",
    "t_v_zipped = list(zip(t_v_text, t_v_labels))\n",
    "random.shuffle(t_v_zipped)\n",
    "t_v_text, t_v_labels = zip(*t_v_zipped)\n",
    "t_v_labels = np.array(t_v_labels)\n",
    "\n",
    "# splitting train, val\n",
    "train_text = t_v_text[:20000]\n",
    "train_labels = np.array(t_v_labels[:20000])\n",
    "val_text = t_v_text[20000:]\n",
    "val_labels = np.array(t_v_labels[20000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'is', 'looking', 'at', 'buying', 'u.k.', 'startup', 'for', '1', 'billion']\n"
     ]
    }
   ],
   "source": [
    "# lowercase and remove punctuation\n",
    "def tokenize(sent):\n",
    "  tokens = tokenizer(sent)\n",
    "  return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "tokens = tokenize(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tokenize_stop_words(sent):\n",
    "#  tokens = tokenizer(sent)\n",
    "#  return [token.text.lower() for token in tokens if (token.text not in (punctuations or STOP_WORDS))]\n",
    "#tokens = tokenize_stop_words(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "#print (tokens)\n",
    "def tokenize_stop_words(parsed):\n",
    "        return [token.text.lower() for token in parsed if (token.text not in (punctuations or STOP_WORDS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_no_cuts(sent):\n",
    "#   tokens = tokenizer(sent)\n",
    "#   return [token.text.lower() for token in tokens]\n",
    "# tokens = tokenize_no_cuts(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "# print (tokens)\n",
    "def tokenize_no_cuts(parsed):\n",
    "    return [token.text.lower() for token in parsed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case_remove_punc(parsed):\n",
    "    return [token.text.lower() for token in parsed if (token.text not in punctuations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset, scheme):\n",
    "    token_dataset = []\n",
    "    # we are keeping track of all tokens in dataset\n",
    "    # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "    for sample in tqdm_notebook(tokenizer.pipe(dataset, disable=['parser', 'tagger', 'ner'], batch_size=512, n_threads=1)):\n",
    "        tokens = scheme(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing val data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b85815ea32b47c8bafc1ca84d0cf7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing test data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15281ac3a81482bb7fc048ae367e387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing train data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207f9e262d6543daafab6a64e5572dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# val set tokens\n",
    "print (\"Tokenizing val data\")\n",
    "val_data_tokens, _ = tokenize_dataset(val_text, lower_case_remove_punc)\n",
    "\n",
    "# test set tokens\n",
    "print (\"Tokenizing test data\")\n",
    "test_data_tokens, _ = tokenize_dataset(test_text, lower_case_remove_punc)\n",
    "\n",
    "# train set tokens\n",
    "print (\"Tokenizing train data\")\n",
    "train_data_tokens, all_train_tokens = tokenize_dataset(train_text, lower_case_remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make n-grams for n= 1-4\n",
    "def tokens_to_ngrams(n, tokens):\n",
    "    ngrams = [\" \".join(tokens[i:i+n]) for i in list(range(len(tokens)-n+1))]\n",
    "    ngrams\n",
    "    return(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_token_list(n, tokens) :\n",
    "    token_list = []\n",
    "    for i in range(n):\n",
    "        ngrams = tokens_to_ngrams(i+1, tokens)\n",
    "        token_list.append(ngrams)\n",
    "    token_list = [i for sublist in token_list for i in sublist]\n",
    "    return(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'is', 'looking', 'at', 'buying', 'u.k.', 'startup', 'for', '1', 'billion']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenize(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "print(get_ngram_token_list(1, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping pickles\n",
    "#pkl.dump(val_data_tokens, open(\"val_data_tokens.p\", \"wb\"))\n",
    "#pkl.dump(test_data_tokens, open(\"test_data_tokens.p\", \"wb\"))\n",
    "#pkl.dump(train_data_tokens, open(\"train_data_tokens.p\", \"wb\"))\n",
    "#pkl.dump(all_train_tokens, open(\"all_train_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_tokens = pkl.load(open(\"train_data_tokens.p\", \"rb\"))\n",
    "#all_train_tokens = pkl.load(open(\"all_train_tokens.p\", \"rb\"))\n",
    "#\n",
    "#val_data_tokens = pkl.load(open(\"val_data_tokens.p\", \"rb\"))\n",
    "#test_data_tokens = pkl.load(open(\"test_data_tokens.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 10000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens, max_vocab_size = 10000):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 5723 ; token jess\n",
      "Token jess; token id 5723\n"
     ]
    }
   ],
   "source": [
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "train_data_indices = token2index_dataset(train_data_tokens)\n",
    "val_data_indices = token2index_dataset(val_data_tokens)\n",
    "test_data_indices = token2index_dataset(test_data_tokens)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200\n",
    "\n",
    "class NewsGroupDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list o newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def newsgroup_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "#train_loader = NewsGroupDataset(train_data_indices, train_targets)\n",
    "#val_loader = NewsGroupDataset(val_data_indices, val_targets)\n",
    "#test_loader = NewsGroupDataset(test_data_indices, test_targets)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = NewsGroupDataset(train_data_indices, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = NewsGroupDataset(val_data_indices, val_labels)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = NewsGroupDataset(test_data_indices, test_labels)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "#for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "#    print (data)\n",
    "#    print (labels)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BagOfWords(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfWords, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,2)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out\n",
    "\n",
    "emb_dim = 100\n",
    "model = BagOfWords(len(id2token), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [101/625], Validation Acc: 79.54\n",
      "Epoch: [1/10], Step: [201/625], Validation Acc: 83.38\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 85.6\n",
      "Epoch: [1/10], Step: [401/625], Validation Acc: 86.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e15fc6e46c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# validate every 100 iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for epoch in range(num_epochs):\n",
    "#    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "#        model.train()\n",
    "#        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "#        optimizer.zero_grad()\n",
    "#        outputs = model(data_batch, length_batch)\n",
    "#        loss = criterion(outputs, label_batch)\n",
    "#        loss.backward()\n",
    "#        optimizer.step()\n",
    "#        # validate every 100 iterations\n",
    "#        if i > 0 and i % 100 == 0:\n",
    "#            # validate\n",
    "#            val_acc = test_model(val_loader, model)\n",
    "#            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "#                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815350\n",
      "20000\n",
      "5000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(all_train_tokens))\n",
    "print(len(train_data_tokens))\n",
    "print(len(val_data_tokens))\n",
    "print(len(test_data_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curve (emb_dim, label_id, vocab = id2token, learning_rate = 0.01, n=1,\n",
    "                            max_vocab_size = 10000, optim_type = 'adam', anneal_rate = 1.0, \n",
    "                            num_epochs = 5, plot_gap = 50):\n",
    "    model = BagOfWords(len(vocab), emb_dim)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if optim_type == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optim_type == \"sgd\":\n",
    "        optimizer = torch.optim.sgd(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    \n",
    "    y = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i >= 0 and i % plot_gap == 0:\n",
    "                # validate\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                #print(val_acc)\n",
    "                y += [val_acc]\n",
    "                #print(i)\n",
    "    print(val_acc)\n",
    "    x = np.arange(0, len(y))\n",
    "    plt.plot(x, y)\n",
    "    plt.xticks(np.arange(0,(625/plot_gap) * (num_epochs +1), (625/plot_gap)), np.arange(0,num_epochs+1))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Validation Accuracy (%)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5100160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_curve(100, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build token tables for :\n",
    "# tokenization schemes (no changes, original, orig + stop words)\n",
    "# ngrams 1-4 (orig+ stop words)\n",
    "# max_vocab_size 200, 500, 1k, 10k, 15k, 30k, 50k, 100k (orig+stop, 4grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store different tokenization schemes in dictionary\n",
    "tokenization_scheme_dict = {'lower_no_punc':{}, 'lower_no_punc_stop':{}, 'lower_only' : {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d29e3394d824c0e8b25a0ec0228ae58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ebb37db33b488aa439dfe8b6650a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ecd9d4e4b84203b0888e4f5c0ac256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lowercase, no puncuation tokens\n",
    "tokenization_scheme_dict['lower_no_punc']['val'], _ = tokenize_dataset(val_text, lower_case_remove_punc)\n",
    "tokenization_scheme_dict['lower_no_punc']['test'], _ = tokenize_dataset(test_text, lower_case_remove_punc)\n",
    "tokenization_scheme_dict['lower_no_punc']['train'], _ = tokenize_dataset(train_text, lower_case_remove_punc)\n",
    "tokenization_scheme_dict['lower_no_punc']['all'] = list(itertools.chain(*tokenization_scheme_dict['lower_no_punc']['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e97b7bca55f446b9bc2561f3b7ae060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002b85c171194680ab5e78138e6f6e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d26eda94824101b744a7ad69a17a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lowercase no puncuation or stop tokens\n",
    "tokenization_scheme_dict['lower_no_punc_stop']['val'], _ = tokenize_dataset(val_text, tokenize_stop_words)\n",
    "tokenization_scheme_dict['lower_no_punc_stop']['test'], _ = tokenize_dataset(test_text, tokenize_stop_words)\n",
    "tokenization_scheme_dict['lower_no_punc_stop']['train'], _ = tokenize_dataset(train_text, tokenize_stop_words)\n",
    "tokenization_scheme_dict['lower_no_punc_stop']['all'] = list(itertools.chain(*tokenization_scheme_dict['lower_no_punc_stop']['train']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbe9a5449fc4e3da5750e73f257b4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7b244811954bd59155801ab1f3eea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7760534ed8924c9a9058e4b33d0382a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lowercase only\n",
    "tokenization_scheme_dict['lower_only']['val'], _ = tokenize_dataset(val_text, tokenize_no_cuts)\n",
    "tokenization_scheme_dict['lower_only']['test'], _ = tokenize_dataset(test_text, tokenize_no_cuts)\n",
    "tokenization_scheme_dict['lower_only']['train'], _ = tokenize_dataset(train_text, tokenize_no_cuts)\n",
    "tokenization_scheme_dict['lower_only']['all'] = list(itertools.chain(*tokenization_scheme_dict['lower_only']['train']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each set of tokens in dictionary create 1-4 ngram lists\n",
    "ngram_dict = {'lower_no_punc':{'n1':{}, 'n2':{}, 'n3':{}, 'n4':{}},\n",
    "             'lower_no_punc_stop':{'n1':{}, 'n2':{}, 'n3':{}, 'n4':{}},\n",
    "             'lower_only':{'n1':{}, 'n2':{}, 'n3':{}, 'n4':{}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "for key1 in ngram_dict:\n",
    "        ngram_dict[key1]['n1']['train'] = [get_ngram_token_list(n,(item)) for item in tokenization_scheme_dict[key1]['train']]\n",
    "        print('done train : {}'.format(key1))\n",
    "        ngram_dict[key1]['n1']['val'] = [get_ngram_token_list(n,(item)) for item in tokenization_scheme_dict[key1]['val']]\n",
    "        print('done val: {}'.format(key1))\n",
    "        ngram_dict[key1]['n1']['test'] = [get_ngram_token_list(n,(item)) for item in tokenization_scheme_dict[key1]['test']]\n",
    "        print('done test: {}'.format(key1))\n",
    "        ngram_dict[key1]['n1']['all'] = list(itertools.chain(*ngram_dict[key1]['n1']['train']))\n",
    "        print('done all: {}'.format(key1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done train : 1\n",
      "done val : 1\n",
      "done test : 1\n",
      "done all : 1\n",
      "done train : 2\n",
      "done val : 2\n",
      "done test : 2\n",
      "done all : 2\n",
      "done train : 3\n",
      "done val : 3\n",
      "done test : 3\n",
      "done all : 3\n",
      "done train : 4\n",
      "done val : 4\n",
      "done test : 4\n",
      "done all : 4\n"
     ]
    }
   ],
   "source": [
    "# loop through dict inserting ngrams tokens\n",
    "# only use best tokenization scheme\n",
    "key1 = 'lower_no_punc_stop'\n",
    "n = 1\n",
    "for key2 in ngram_dict[key1]:\n",
    "    ngram_dict[key1][key2]['train'] = [get_ngram_token_list(n,(item)) for item in tokenization_scheme_dict[key1]['train']]\n",
    "    print('done train : {}'.format(n))\n",
    "    ngram_dict[key1][key2]['val'] = [get_ngram_token_list(n,(item)) for item in tokenization_scheme_dict[key1]['val']]\n",
    "    print('done val : {}'.format(n))\n",
    "    ngram_dict[key1][key2]['test'] = [get_ngram_token_list(n,(item)) for item in tokenization_scheme_dict[key1]['test']]\n",
    "    print('done test : {}'.format(n))\n",
    "    ngram_dict[key1][key2]['all'] = list(itertools.chain(*ngram_dict[key1][key2]['train']))\n",
    "    print('done all : {}'.format(n))\n",
    "    n += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-53b033e2df3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#pkl.dump(ngram_dict, open(\"colins_tokens_n1_only.p\", \"wb\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"colins_tokens_2.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "#pkl.dump(ngram_dict, open(\"colins_tokens_n1_only.p\", \"wb\"))\n",
    "pkl.dump(ngram_dict, open(\"colins_tokens_2.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 85.216\n"
     ]
    }
   ],
   "source": [
    "val_acc = test_model(test_loader, model)\n",
    "print(\"test acc: {}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.02\n",
      "84.54\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdoAAAEWCAYAAADBzlZgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f50d34a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot tokenization schemes using n1\n",
    "for key in ngram_dict:\n",
    "    token2id, id2token = build_vocab(ngram_dict[key]['n1']['all'])\n",
    "    train_data_indices = token2index_dataset(ngram_dict[key]['n1']['train'])\n",
    "    val_data_indices= token2index_dataset(ngram_dict[key]['n1']['val'])\n",
    "    #test_data_indices = token2index_dataset(ngram_dict[key1]['n1']['test'])\n",
    "    \n",
    "    train_dataset = NewsGroupDataset(train_data_indices, train_labels)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    val_dataset = NewsGroupDataset(val_data_indices, val_labels)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "    #skip test data for now\n",
    "    #test_dataset = NewsGroupDataset(test_data_indices, test_labels)\n",
    "    #test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "    #                                           batch_size=BATCH_SIZE,\n",
    "    #                                           collate_fn=newsgroup_collate_func,\n",
    "    #                                           shuffle=False)\n",
    "    plot_training_curve(100, str(key), num_epochs=5)\n",
    "    plt.legend()\n",
    "    plt.title(\"Validation Accuracy of Models Trained with Different Tokenization Schemes \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "# now vary ngrams\n",
    "n_list = ['n1', 'n2', 'n3', 'n4']\n",
    "for key in n_list:\n",
    "    token2id, id2token = build_vocab(ngram_dict['lower_no_punc_stop'][key]['all'])\n",
    "    train_data_indices = token2index_dataset(ngram_dict['lower_no_punc_stop'][key]['train'])\n",
    "    val_data_indices= token2index_dataset(ngram_dict['lower_no_punc_stop'][key]['val'])\n",
    "    #test_data_indices = token2index_dataset(ngram_dict[key1]['n1']['test'])\n",
    "    \n",
    "    train_dataset = NewsGroupDataset(train_data_indices, train_labels)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    val_dataset = NewsGroupDataset(val_data_indices, val_labels)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "    #skip test data for now\n",
    "    #test_dataset = NewsGroupDataset(test_data_indices, test_labels)\n",
    "    #test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "    #                                           batch_size=BATCH_SIZE,\n",
    "    #                                           collate_fn=newsgroup_collate_func,\n",
    "    #                                           shuffle=False)\n",
    "    plot_training_curve(100, str(key), num_epochs=5)\n",
    "    plt.legend()\n",
    "    plt.title(\"Validation Accuracy of Models Trained with Different Ngrams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now vary vocab size\n",
    "max_vocab_size_list = [100, 1000, 10000, 50000, 60000]\n",
    "for size in max_vocab_size_list:\n",
    "    token2id, id2token = build_vocab(ngram_dict['lower_no_punc_stop']['n?']['all'], max_vocab_size = size)\n",
    "    train_data_indices = token2index_dataset(ngram_dict['lower_no_punc_stop']['n?']['train'])\n",
    "    val_data_indices= token2index_dataset(ngram_dict['lower_no_punc_stop']['n?']['val'])\n",
    "    #test_data_indices = token2index_dataset(ngram_dict[key1]['n1']['test'])\n",
    "    \n",
    "    train_dataset = NewsGroupDataset(train_data_indices, train_labels)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    val_dataset = NewsGroupDataset(val_data_indices, val_labels)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "    #skip test data for now\n",
    "    #test_dataset = NewsGroupDataset(test_data_indices, test_labels)\n",
    "    #test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "    #                                           batch_size=BATCH_SIZE,\n",
    "    #                                           collate_fn=newsgroup_collate_func,\n",
    "    #                                           shuffle=False)\n",
    "    plot_training_curve(100, label_id = str(size))\n",
    "plt.legend()\n",
    "plt.title(\"Validation Accuracy of Models Trained with Different Vocab Size \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now vary embedding size:\n",
    "embd_size_list = [10, 100, 500, 1000]\n",
    "for embd_size in embd_size_list:\n",
    "    token2id, id2token = build_vocab(ngram_dict['lower_no_punc_stop']['n?']['all'], max_vocab_size = ???)\n",
    "    train_data_indices = token2index_dataset(ngram_dict['lower_no_punc_stop']['n?']['train'])\n",
    "    val_data_indices= token2index_dataset(ngram_dict['lower_no_punc_stop']['n?']['val'])\n",
    "    #test_data_indices = token2index_dataset(ngram_dict[key1]['n1']['test'])\n",
    "    \n",
    "    train_dataset = NewsGroupDataset(train_data_indices, train_labels)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    val_dataset = NewsGroupDataset(val_data_indices, val_labels)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "    plot_training_curve(embd_size, label_id = str(embd_size), max_vocab_size = ?????)\n",
    "plt.legend()\n",
    "plt.title(\"Validation Accuracy of Models Trained with Different Embedding Sizes\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now vary optimizer:\n",
    "plot_training_curve(embd_size, label_id = 'adam', optim_type = 'adam')\n",
    "plot_training_curve(embd_size, label_id = 'sgd', optim_type = 'sgd')\n",
    "plt.title(\"Validation Accuracy of Models Trained with Different Optimizer Types\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now vary learning rate:\n",
    "lr_list = [0.001, 0.01, 0.1]\n",
    "for rate in lr_list:\n",
    "    plot_training_curve(embd_size, label_id = str(rate), optim_type = 'adam????', learning_rate = rate)\n",
    "plt.title(\"Validation Accuracy of Models Trained with Different Learning Rates\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now vary annealing:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
